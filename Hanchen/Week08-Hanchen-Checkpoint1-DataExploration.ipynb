{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ae4d73",
   "metadata": {},
   "source": [
    "# Assignment 2 - Individual Checkpoint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b3bdc",
   "metadata": {},
   "source": [
    "**Author**: Hanchen Wang\n",
    "\n",
    "**Group ID**: CC08-3\n",
    "\n",
    "**Driving problem**: Do they avoid inactivity in at least 10 hours a day?\n",
    "\n",
    "**Overview of the work**: \n",
    "-   By analysing three csv datasets *dailySteps_merged*, *hourlySteps_merged* and *minuteStepsWide_merged*, I will explore the data for participants with id *1503960366*, *1624580081* and *1644430081* and report all aspects required including the number of days of data, daily step count information and minute step count information. \n",
    "-   While completing my exploration of the data for three people agreed with my group, Literate Programming is strictly applied to my Jupyter Notebook committed to Github.\n",
    "\n",
    "**Initial assumptions & predictions**: \n",
    "-   The participants in three datasets are consistent. (Has been confirmed in data analysis.)\n",
    "-   There are independence between different participants in all datasets. (Depends on the data collection process, we assume this is true.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8894d1f",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e8dba",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "start_date: 11/9/2024\n",
    "end_date: 11/9/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e52887",
   "metadata": {},
   "source": [
    "Three datasets are provided and they are stored in the **src** folder.\n",
    "\n",
    "We use the **read_csv** function in pandas to read them as dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88257c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "# Read three CSV files from the 'src' folder\n",
    "df_day = pd.read_csv('src/dailySteps_merged.csv')\n",
    "df_hour = pd.read_csv('src/hourlySteps_merged.csv')\n",
    "df_min = pd.read_csv('src/minuteStepsWide_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec593936",
   "metadata": {},
   "source": [
    "All three datasets have been successfully loaded and we can access them using **df_day**, **df_hour** and **df_min**.\n",
    "Let's have an overview of those datasets by printing their size and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "705f002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of daily dataset: 940 rows and 3 columns.\n",
      "The column names of daily dataset: Id, ActivityDay, StepTotal\n",
      "\n",
      "The size of hourly dataset: 22099 rows and 3 columns.\n",
      "The column names of hourly dataset: Id, ActivityHour, StepTotal\n",
      "\n",
      "The size of minute dataset: 21645 rows and 62 columns.\n",
      "The column names of minute dataset: Id, ActivityHour, Steps00, Steps01, Steps02, Steps03, Steps04, Steps05, Steps06, Steps07, Steps08, Steps09, Steps10, Steps11, Steps12, Steps13, Steps14, Steps15, Steps16, Steps17, Steps18, Steps19, Steps20, Steps21, Steps22, Steps23, Steps24, Steps25, Steps26, Steps27, Steps28, Steps29, Steps30, Steps31, Steps32, Steps33, Steps34, Steps35, Steps36, Steps37, Steps38, Steps39, Steps40, Steps41, Steps42, Steps43, Steps44, Steps45, Steps46, Steps47, Steps48, Steps49, Steps50, Steps51, Steps52, Steps53, Steps54, Steps55, Steps56, Steps57, Steps58, Steps59\n"
     ]
    }
   ],
   "source": [
    "# Access the size of data set using .shape[0] and .shape[1]\n",
    "# As .columns return a list of column name, use ',' to join them as a string\n",
    "print(\"The size of daily dataset:\", df_day.shape[0], \"rows and\", df_day.shape[1], \"columns.\" )\n",
    "print(\"The column names of daily dataset:\", \", \".join(df_day.columns))\n",
    "print()\n",
    "print(\"The size of hourly dataset:\", df_hour.shape[0], \"rows and\", df_hour.shape[1], \"columns.\" )\n",
    "print(\"The column names of hourly dataset:\", \", \".join(df_hour.columns))\n",
    "print()\n",
    "print(\"The size of minute dataset:\", df_min.shape[0], \"rows and\", df_min.shape[1], \"columns.\" )\n",
    "print(\"The column names of minute dataset:\", \", \".join(df_min.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d763c",
   "metadata": {},
   "source": [
    "All datasets share the **Id** column.\n",
    "\n",
    "Both daily dataset and hourly dataset have **StepTotal** allowing for easy accessing and direct calculation.\n",
    "\n",
    "In contrast, the minute dataset is more complex as it has **60 columns** to record step count for one row, which requires extra data manipulation processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeaab3b",
   "metadata": {},
   "source": [
    "### Check Missing Values\n",
    "start_date: 11/9/2024\n",
    "end_date: 11/9/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd22ef",
   "metadata": {},
   "source": [
    "Before doing any data analysis, we need to make sure all missing values in three datasets are handled properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af808c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id             False\n",
       "ActivityDay    False\n",
       "StepTotal      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True will be displayed if any of the column has missing value\n",
    "df_day.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84974d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              False\n",
       "ActivityHour    False\n",
       "StepTotal       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hour.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1159feb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              False\n",
       "ActivityHour    False\n",
       "Steps00         False\n",
       "Steps01         False\n",
       "Steps02         False\n",
       "                ...  \n",
       "Steps55         False\n",
       "Steps56         False\n",
       "Steps57         False\n",
       "Steps58         False\n",
       "Steps59         False\n",
       "Length: 62, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a0b12",
   "metadata": {},
   "source": [
    "Since results for all columns are **False**, there are **no missing values** throughout the three datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac5fcd",
   "metadata": {},
   "source": [
    "### Check Assumption\n",
    "start_date: 11/9/2024\n",
    "end_date: 11/9/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001aa90",
   "metadata": {},
   "source": [
    "Firsly, I want to understand the nature of these datasets as well as checking my initial assumption for three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a68f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the number of unique ids in daily, hour, minute datasets correspondingly? 33 33 33\n",
      "Are unique ids in daily dataset and hour dataset the same? True\n",
      "Are unique ids in daily dataset and minute dataset the same? True\n"
     ]
    }
   ],
   "source": [
    "# Check if unique ids are the same for three datasets\n",
    "unique_ids_day = df_day['Id'].unique()\n",
    "unique_ids_hour = df_hour['Id'].unique()\n",
    "unique_ids_min = df_min['Id'].unique()\n",
    "\n",
    "print(\"What are the number of unique ids in daily, hour, minute datasets correspondingly?\", \n",
    "      len(unique_ids_day), len(unique_ids_hour), len(unique_ids_min))\n",
    "print(\"Are unique ids in daily dataset and hour dataset the same?\", set(unique_ids_day) == set(unique_ids_hour))\n",
    "print(\"Are unique ids in daily dataset and minute dataset the same?\", set(unique_ids_day) == set(unique_ids_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c4f725",
   "metadata": {},
   "source": [
    "According to the printing message above, values in column **Id** are consistent across three different datasets, which confirms my initial assumption: **The participants in three datasets are consistent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4c185",
   "metadata": {},
   "source": [
    "### What is the number of days of data for these 3 people?\n",
    "start_date: 11/9/2024\n",
    "end_date: 11/9/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0df27",
   "metadata": {},
   "source": [
    "Now it's time to begin analysing and prepare the report for three selected people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1acbcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids of three people I'll focus on: 1503960366 1624580081 1644430081\n",
      "The number of days of data for these 3 people: 31 31 30\n"
     ]
    }
   ],
   "source": [
    "# Use index 0,1,2 to extract first three value from the list of unique id\n",
    "id1 = unique_ids_day[0]\n",
    "id2 = unique_ids_day[1]\n",
    "id3 = unique_ids_day[2]\n",
    "\n",
    "# Filter the rows in df_day with corresponding value in 'Id' column using isin()\n",
    "# Extract 'ActivityDay' column from df_day for id1, id2, id3 using indexing\n",
    "id1_activity_day = df_day[df_day['Id'].isin([id1])]['ActivityDay']\n",
    "id2_activity_day = df_day[df_day['Id'].isin([id2])]['ActivityDay']\n",
    "id3_activity_day = df_day[df_day['Id'].isin([id3])]['ActivityDay']\n",
    "\n",
    "# Use len() to find out the number of days in the list\n",
    "# Use unique() to avoid duplicates\n",
    "id1_num_of_days = len(id1_activity_day.unique())\n",
    "id2_num_of_days = len(id2_activity_day.unique())\n",
    "id3_num_of_days = len(id3_activity_day.unique())\n",
    "\n",
    "# Print out result\n",
    "print(\"Ids of three people I'll focus on:\", id1, id2, id3)\n",
    "print(\"The number of days of data for these 3 people:\", id1_num_of_days, id2_num_of_days, id3_num_of_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522dd77d",
   "metadata": {},
   "source": [
    "The result shows a variation in the number of days of data for these 3 people, which could be important to note for further analysis, especially if consistency in the number of days is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263fbf5",
   "metadata": {},
   "source": [
    "### Daily step count information\n",
    "start_date: 11/9/2024\n",
    "end_date: 11/9/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47455214",
   "metadata": {},
   "source": [
    "Let's compute daily average, maximum, minimum, median step count for these 3 people.\n",
    "\n",
    "We begin with filtering the dataframe using **id1**, **id2** and **id3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b8448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Daily Average Step  Daily Max Steps  Daily Min Steps  \\\n",
      "0  1503960366               12116            18134                0   \n",
      "1  1624580081                5743            36019             1510   \n",
      "2  1644430081                7282            18213             1223   \n",
      "\n",
      "   Daily Median Steps  \n",
      "0               12207  \n",
      "1                4026  \n",
      "2                6683  \n"
     ]
    }
   ],
   "source": [
    "# Filter the rows in df_day with corresponding value in 'Id' column using isin()\n",
    "# Extract 'StepTotal' column from df_day for id1, id2, id3 using indexing\n",
    "id1_daily_step_total = df_day[df_day['Id'].isin([id1])]['StepTotal']\n",
    "id2_daily_step_total = df_day[df_day['Id'].isin([id2])]['StepTotal']\n",
    "id3_daily_step_total = df_day[df_day['Id'].isin([id3])]['StepTotal']\n",
    "\n",
    "# Calculate average step count per day\n",
    "id1_avg_daily_step_count = int(id1_daily_step_total.mean())\n",
    "id2_avg_daily_step_count = int(id2_daily_step_total.mean())\n",
    "id3_avg_daily_step_count = int(id3_daily_step_total.mean())\n",
    "\n",
    "# Calculate maximum step count\n",
    "id1_max_daily_step_count = int(id1_daily_step_total.max())\n",
    "id2_max_daily_step_count = int(id2_daily_step_total.max())\n",
    "id3_max_daily_step_count = int(id3_daily_step_total.max())\n",
    "\n",
    "# Calculate minimum step count\n",
    "id1_min_daily_step_count = int(id1_daily_step_total.min())\n",
    "id2_min_daily_step_count = int(id2_daily_step_total.min())\n",
    "id3_min_daily_step_count = int(id3_daily_step_total.min())\n",
    "\n",
    "# one other observation: Calculate median step count\n",
    "id1_med_daily_step_count = int(id1_daily_step_total.median())\n",
    "id2_med_daily_step_count = int(id2_daily_step_total.median())\n",
    "id3_med_daily_step_count = int(id3_daily_step_total.median())\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "daily_result = {\n",
    "    'ID': [id1, id2, id3],\n",
    "    'Daily Average Step': [id1_avg_daily_step_count, id2_avg_daily_step_count, id3_avg_daily_step_count],\n",
    "    'Daily Max Steps': [id1_max_daily_step_count, id2_max_daily_step_count, id3_max_daily_step_count],\n",
    "    'Daily Min Steps': [id1_min_daily_step_count, id2_min_daily_step_count, id3_min_daily_step_count],\n",
    "    'Daily Median Steps': [id1_med_daily_step_count, id2_med_daily_step_count, id3_med_daily_step_count]\n",
    "}\n",
    "\n",
    "# Create the dataframe for printing as a table\n",
    "table_day = pd.DataFrame(daily_result)\n",
    "\n",
    "# Display the table\n",
    "print(table_day)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f7250",
   "metadata": {},
   "source": [
    "Using in-built functions including mean(), max(), min() and median(), all daily step count information needed are extracted and stored in variables with corresponding resonable names. \n",
    "\n",
    "Considering the context that all step count data are stored in integers, int() is used to round the calculation result.\n",
    "\n",
    "From the result shown in the table above, it suggests:\n",
    "- The user id 1503960366 is consistently active and has a steady daily step count.\n",
    "- The user id 1624580081 appears to have some intense days of high activity level but otherwise remains much less active on average.\n",
    "- The user id 1644430081 shows a moderate daily activity level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed87ec",
   "metadata": {},
   "source": [
    "### Minute step count information\n",
    "start_date: 12/9/2024\n",
    "end_date: 13/9/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae0fce",
   "metadata": {},
   "source": [
    "Due to the higher complexity of the minute dataset, we need to define functions to avoid repetitive code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e686b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count number of non-zero minutes\n",
    "def non_zero_minutes_counter(df):\n",
    "    # Extract all columns start with 'Steps'\n",
    "    # Flatten the dataframe into a list\n",
    "    step_cols = [col for col in df.columns if col.startswith('Steps')]\n",
    "    \n",
    "    # Check if value in the step columns is greater than 0 \n",
    "    # Use first sum() to count non-zero values per row\n",
    "    # Use second sum() to aggregate across all rows\n",
    "    non_zero_count = (df[step_cols] > 0).sum().sum()\n",
    "    \n",
    "    # Return the total number of non-zero step values as an integer\n",
    "    return int(non_zero_count)\n",
    "\n",
    "# Function to count missing value\n",
    "def missing_minutes_counter(df):\n",
    "    # Extract & Flatten (Same as above)\n",
    "    step_cols = [col for col in df.columns if col.startswith('Steps')]\n",
    "\n",
    "    # Use isnull() to check for missing values\n",
    "    # Use sum() to count them across all columns\n",
    "    missing_count = df[step_cols].isnull().sum().sum()\n",
    "\n",
    "    # Return the total number of missing values as an integer\n",
    "    return int(missing_count)\n",
    "\n",
    "# Function to calculate average steps per minute\n",
    "def avg_steps_per_minute_calculator(df):\n",
    "    # Extract & Flatten (Same as above)\n",
    "    step_cols = [col for col in df.columns if col.startswith('Steps')]\n",
    "    \n",
    "    # Compute the total sum of steps\n",
    "    # Divide by the total number of valid (non-missing) entries\n",
    "    avg_val = df[step_cols].sum().sum() / df[step_cols].count().sum()\n",
    "\n",
    "    # Return the average as an integer\n",
    "    return int(avg_val)\n",
    "\n",
    "\n",
    "# Function to calculate maximum and minimum steps\n",
    "def max_min_steps_per_minute_calculator(df):\n",
    "    # Extract & Flatten (Same as above)\n",
    "    step_cols = [col for col in df.columns if col.startswith('Steps')]\n",
    "\n",
    "    # Use first max() used to find maximum in each column\n",
    "    # Use second max() used to find maximum of the maximums\n",
    "    max_val = df[step_cols].max().max()\n",
    "\n",
    "    # Use first min() to find minimum in each column\n",
    "    # Use second min() to find minimum of the minimums\n",
    "    min_val = df[step_cols].min().min()\n",
    "\n",
    "    # Return both the maximum and minimum as integers\n",
    "    return int(max_val), int(min_val)\n",
    "\n",
    "\n",
    "# one other observation: Function to calculate standard deviation of step count\n",
    "def sd_steps_per_minute_calculator(df):\n",
    "    # Extract & Flatten (Same as above)\n",
    "    step_cols = [col for col in df.columns if col.startswith('Steps')]\n",
    "    \n",
    "    # Use stack() to flatten all columns into one \n",
    "    # Use std() to calculate the standard deviation\n",
    "    sd = df[step_cols].stack().std()\n",
    "\n",
    "    # Return the standard deviation as an integer\n",
    "    return int(sd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b70f7",
   "metadata": {},
   "source": [
    "All the functions needed have been defined above.\n",
    "\n",
    "We then need to filter out the df_min for id1, id2 and id3 individually for the input of those functions.\n",
    "\n",
    "Finally, apply the functions and save the results into variables with reasonable names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13dc7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Non-Zero Minutes  Missing Minutes  Minute Average Steps  \\\n",
      "0  1503960366              8311                0                     8   \n",
      "1  1624580081              3679                0                     3   \n",
      "2  1644430081              5978                0                     5   \n",
      "\n",
      "   Minute Max Steps  Minute Min Steps  Minute Standard Deviation of Steps  \n",
      "0               165                 0                                  25  \n",
      "1               184                 0                                  17  \n",
      "2               134                 0                                  17  \n"
     ]
    }
   ],
   "source": [
    "# Filter the rows in df_min with corresponding value in 'Id' column using isin()\n",
    "id1_minutes = df_min[df_min['Id'].isin([id1])]\n",
    "id2_minutes = df_min[df_min['Id'].isin([id2])]\n",
    "id3_minutes = df_min[df_min['Id'].isin([id3])]\n",
    "\n",
    "\n",
    "# Apply all functions above for three people using filtered dataframes\n",
    "id1_non_zero_minutes = non_zero_minutes_counter(id1_minutes)\n",
    "id2_non_zero_minutes = non_zero_minutes_counter(id2_minutes)\n",
    "id3_non_zero_minutes = non_zero_minutes_counter(id3_minutes)\n",
    "\n",
    "id1_missing_minute = missing_minutes_counter(id1_minutes)\n",
    "id2_missing_minute = missing_minutes_counter(id2_minutes)\n",
    "id3_missing_minute = missing_minutes_counter(id3_minutes)\n",
    "\n",
    "id1_avg_step_count = avg_steps_per_minute_calculator(id1_minutes)\n",
    "id2_avg_step_count = avg_steps_per_minute_calculator(id2_minutes)\n",
    "id3_avg_step_count = avg_steps_per_minute_calculator(id3_minutes)\n",
    "\n",
    "id1_max_minute_step_count, id1_min_minute_step_count = max_min_steps_per_minute_calculator(id1_minutes)\n",
    "id2_max_minute_step_count, id2_min_minute_step_count = max_min_steps_per_minute_calculator(id2_minutes)\n",
    "id3_max_minute_step_count, id3_min_minute_step_count = max_min_steps_per_minute_calculator(id3_minutes)\n",
    "\n",
    "id1_sd_minute_step_count = sd_steps_per_minute_calculator(id1_minutes)\n",
    "id2_sd_minute_step_count = sd_steps_per_minute_calculator(id2_minutes)\n",
    "id3_sd_minute_step_count = sd_steps_per_minute_calculator(id3_minutes)\n",
    "\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "minute_result = {\n",
    "    'ID': [id1, id2, id3],\n",
    "    'Non-Zero Minutes': [id1_non_zero_minutes, id2_non_zero_minutes, id3_non_zero_minutes],\n",
    "    'Missing Minutes': [id1_missing_minute, id2_missing_minute, id3_missing_minute],\n",
    "    'Minute Average Steps': [id1_avg_step_count, id2_avg_step_count, id3_avg_step_count],\n",
    "    'Minute Max Steps': [id1_max_minute_step_count, id2_max_minute_step_count, id3_max_minute_step_count],\n",
    "    'Minute Min Steps': [id1_min_minute_step_count, id2_min_minute_step_count, id3_min_minute_step_count],\n",
    "    'Minute Standard Deviation of Steps': [id1_sd_minute_step_count, id2_sd_minute_step_count, id3_sd_minute_step_count]\n",
    "}\n",
    "\n",
    "# Create the dataframe for printing as a table\n",
    "table_minute = pd.DataFrame(minute_result)\n",
    "\n",
    "# Display the table\n",
    "print(table_minute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1a49de",
   "metadata": {},
   "source": [
    "\n",
    "According to the result table of minute step count information above, we can see some patterns:\n",
    "- The user id 1503960366 is the most active among three people due to the highest non-zero minutes of 8311 and average steps per minute of 8. This user's  standard deviation of step count of 25 indicates higher variability in acitivity levels than other two users.\n",
    "- Although user id 1624580081 has the maximum step count in one minute of 184, this person is still the least active user due to its lowest non-zero minutes of 3679 and average step count of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2114e2a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "start_date: 13/9/2024\n",
    "end_date: 13/9/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed4228",
   "metadata": {},
   "source": [
    "In this checkpoint 1, we performed an initial exploration of the step count data focusing on three people. After calculating all information needed, they are saved into two dataframes **table_day** and **table_minute**, available for further analysis in next checkpoint such as data visualization.\n",
    "\n",
    "As a final statement, I learnt there is no missing values throughout three datasets, while variations in the number of days of data recorded for different participants and their activity level appear to be obvious. This highly relates to my driving problem \"Do they avoid inactivity in at least 10 hours a day?\":\n",
    "\n",
    "1. Since there are no missing values, I can confidently analyze the step data without concerns about incomplete records, ensuring a realiable analysis result.\n",
    "2. The varying number of days recorded for different participants suggests that some individuals have more or less data available for analysis, which can affect the accuracy of the conclusions of their activity pattern over time.\n",
    "3. Based on an initial data exploration for three people, I discovered that while some participants are active for more than 10 hours a day, some may struggle to maintain a consistent active level. Such variations deserve more data anlysis for understanding the activity level in this group of participants and producing meaningful results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
